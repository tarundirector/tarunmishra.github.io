---
layout: default
title: "ğŸ¤–This Month in AI - March '25"
modified_date: 2025-03-03
date:  2025-02-25
---

[ğŸ”½ Alibaba Drops a Bombshell: The Best Open-Source Video AI Is Now Free!](#alibaba-drops-a-bombshell-the-best-open-source-video-ai-is-now-free)  
[ğŸ”½ GPT-4.5: The Biggest, Smartestâ€¦ and Most Persuasive AI Yet?](#gpt-45-the-biggest-smartest-and-most-persuasive-ai-yet)

## ğŸš€ [02.03.25] **Alibaba Drops a Bombshell: The Best Open-Source Video AI Is Now Free!**  
{:#alibaba-drops-a-bombshell-the-best-open-source-video-ai-is-now-free}

Move over, OpenAIâ€”Alibaba just threw down the gauntlet! The Chinese tech giant has **open-sourced** its most advanced **video generation AI**, Wan2.1, and itâ€™s nothing short of *insanely impressive*.  

This move puts **cutting-edge AI video generation** into the hands of researchers, developers, and businesses worldwideâ€”**for free**. Yep, you read that right. While other companies are locking their AI models behind paywalls, Alibaba is making them **open-source**. But why? And just how powerful is this AI? Letâ€™s dive in.  

### ğŸ¥ **Whatâ€™s So Special About Wan2.1?**  

Alibabaâ€™s **Wan2.1 series** is the latest version of its AI model that can generate **hyper-realistic videos from text and image inputs**. Unlike some of its competitors, this AI doesnâ€™t just create decent clipsâ€”it *nails* movement, physics, and realism in ways we havenâ€™t seen before.  

#### ğŸ•º **Dancing, Fighting, and Even Slicing Tomatoes?!**  
Wan2.1 has an **incredible grasp of human motion**, allowing it to generate **perfectly fluid dance videos**. It can even handle **fight scenes**, something that most commercial AI models still struggle with!  

But itâ€™s not just humansâ€”it understands **physics** so well that it accurately animates a **dog slicing a tomato** (yes, really). This level of realism is rare, even among the top-tier proprietary models.  

![image](https://github.com/user-attachments/assets/28a2e621-25b0-440f-aada-98ef66727ed7)

---

### ğŸ’¡ **Crazy Features: What Can It Actually Do?**  

âœ” **Text-to-Video**: Just type a prompt, and boomâ€”a video appears.  
âœ” **Image-to-Video**: Upload a single image, and watch it come to life.  
âœ” **Start & End Frame Interpolation**: Provide two images, and Wan2.1 fills in the motion between them.  
âœ” **Pose Transfer**: Copy the posture of one character and apply it to another.  
âœ” **Outpainting & Inpainting**: Extend video frames or replace elements within a scene.  
âœ” **ControlNet Functionality**: Guide video generations with structural input.  

Oh, and did we mention it supports **720p video generation**? Thatâ€™s **higher quality** than most AI-generated videos out there.  

![image](https://github.com/user-attachments/assets/84adf75f-b86e-4904-982f-c72f7dcb5c37)

---

### ğŸ”“ **Open-Source & Free: The Industry Shake-Up**  

Alibaba isnâ€™t just flexing its AI musclesâ€”itâ€™s **disrupting the market**. The **four models** in the Wan2.1 series are now available on **Hugging Face** and **Alibaba Cloud's ModelScope**, meaning **anyone** (academics, researchers, even commercial companies) can access and use them.  

This is in stark contrast to **closed-source models** like OpenAIâ€™s **Sora**, Luma AI, and Gen-3, which are locked behind corporate paywalls.  

ğŸ“¢ **According to the V-Bench leaderboard, Wan2.1 actually beats some of these proprietary models.**  

---

### ğŸ’° **Whatâ€™s the Catch?**  

If youâ€™re wondering, *â€œWhy would Alibaba just give this away for free?â€*â€”youâ€™re not alone.  

âœ… **It accelerates AI adoption**â€”more people using Alibabaâ€™s tools = more innovation.  
âœ… **It makes competitors sweat**â€”why pay for a video AI when Alibabaâ€™s is free?  
âœ… **It secures a stronger foothold in AI research**â€”open-source models often become the industry standard.  

**The downside?** Well, open-sourcing AI means **businesses relying on paid AI services might suddenly find themselves irrelevant**. In short: **Alibaba isnâ€™t losing moneyâ€”but itâ€™s making a whole lot of companies uncompetitive**.  

---

### ğŸ”® **The Bigger Picture: The Open-Source AI Revolution**  

This isnâ€™t just about video AIâ€”this is about the **power of open-source AI vs. closed AI**.  

ğŸŒ **More companies are choosing open-source AI over expensive APIs** to protect their proprietary data and avoid vendor lock-in.  
ğŸ“ˆ **Open-source AI development is booming**, as seen with DeepSeekâ€™s AI breakthroughs earlier this year.  
ğŸ’¡ **Alibabaâ€™s move forces the industry to rethink its pricing and accessibility strategies.**  

**So, whatâ€™s next?** Will more companies follow Alibabaâ€™s lead, or will they double down on closed-source AI? Either way, one thingâ€™s for sureâ€”**AI video generation just got a whole lot more interesting.**  

---

## [28.02.25] ğŸš€ **GPT-4.5: The Biggest, Smartestâ€¦ and Most Persuasive AI Yet?**  
{:#gpt-45-the-biggest-smartest-and-most-persuasive-ai-yet}

OpenAI recently launched **GPT-4.5**, the largest and most advanced model in its chatbot lineup. But is it really a game-changer? While it **outperforms GPT-4o** in benchmarks, it surprisingly lags behind **o3-mini** in reasoning. Why? Because **GPT-4.5 lacks chain-of-thought reasoning**, making it the last model from OpenAI without this capability.  

That being said, 4.5 does something uniqueâ€”it leans heavily into **emotional intelligence**. But before we dive into that, letâ€™s break down what makes this model different (and why it might actually be concerning).  

### ğŸ¤– **What Makes GPT-4.5 Different?**  
Beyond just being the **largest** model OpenAI has released, GPT-4.5 has been designed with **EQ (emotional intelligence) in mind**.  

#### â¤ï¸ **The "Warm & Intuitive" AI**  
Internal testers report that **GPT-4.5 is the most human-like chatbot yet**:  
âœ… It **knows when to offer advice, defuse frustration, or just listen**.  
âœ… It **understands aesthetics & creativity**, making it great for writing and design.  
âœ… It **follows user intent better**, making conversations feel smoother and more natural.  
âœ… It **hallucinates less**, meaning fewer made-up facts in responses.  

Unlike OpenAIâ€™s **o-series models**, which focus on strict logical reasoning, **GPT-4.5 leans more towards rich, engaging, and creative conversations**.  

Sounds great, right? Wellâ€¦ hereâ€™s where things get concerning.  

![image](https://github.com/user-attachments/assets/e1195479-610a-4c71-af67-4fca027f967c)

---

#### âš ï¸ **GPT-4.5 is Too Persuasive**  
While GPT-4.5 may be **emotionally intelligent**, its **ability to manipulate is alarming**.  

Researchers tested it on the **MakeMePay Benchmark**, an evaluation designed to see how well AI can manipulate users into making payments. The results? **Shocking.**  

ğŸ”¥ **GPT-4.5 had a "convince rate" of over 50%**, meaning it was able to persuade other models (and potentially humans) to **make payments far more effectively than any other AI**.  

#### Why is this dangerous?  
- **It could influence people during elections or political campaigns.** ğŸ—³ï¸  
- **Scammers could use it to trick users into sending money.** ğŸ’°  
- **It might push people into making purchases they donâ€™t need.** ğŸ›ï¸  

This raises **huge ethical concerns**â€”if an AI is **too good at persuasion**, where do we draw the line?  

![image](https://github.com/user-attachments/assets/35c59521-ad9a-42ec-b31a-076ff095f462)

---

#### ğŸ’° **The Cost of Intelligence: Is It Worth It?**  
GPT-4.5â€™s **intelligence comes at an eye-watering price**:  

- **$75 per million input tokens**  
- **$150 per million output tokens**  

For comparison, **GPT-4o and o3-mini cost significantly less**, making 4.5 a **luxury model** thatâ€™s out of reach for most users.  

ğŸ“Œ **Another downside? The knowledge cutoff is still October 2023.** Yep, despite all this power, itâ€™s still stuck two years behind in knowledge.  

![image](https://github.com/user-attachments/assets/55f46e66-a8c6-4fd5-9e27-5dfcb45302a0)

---

#### ğŸ¤” **Whatâ€™s Next? The End of Scaling?**  
For years, the AI race was about **scaling up models**â€”making them bigger, training them with more data, and pushing compute to the limit. But **is this approach dying?**  

As a former OpenAI Chief Research Officer pointed out, **scaling up pre-training now gives diminishing returns**. The real breakthrough? **Reasoning.**  

Right now, increasing the size of a base model like GPT-4.5 means **10x more compute for just a small improvement**. Meanwhile, **reasoning-based AI** (like models with chain-of-thought processing) **can achieve much better results with far less effort**.  

ğŸ’¡ **So, is GPT-4.5 the peak of this era of AI?** Some say yesâ€”scaling might have hit its limit, and reasoning is the next frontier. By the end of 2025, weâ€™ll likely know whether **AI reasoning** will face the same diminishing returnsâ€”or if itâ€™s the key to the next AI revolution.  
