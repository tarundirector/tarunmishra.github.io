---
layout: default
title: "🤖This Month in AI - March '25"
modified_date: 2025-03-03
date:  2025-02-25
---

[🔽 Alibaba Drops a Bombshell: The Best Open-Source Video AI Is Now Free!](#alibaba-drops-a-bombshell-the-best-open-source-video-ai-is-now-free)  
[🔽 GPT-4.5: The Biggest, Smartest… and Most Persuasive AI Yet?](#gpt-45-the-biggest-smartest-and-most-persuasive-ai-yet)

## 🚀 [02.03.25] **Alibaba Drops a Bombshell: The Best Open-Source Video AI Is Now Free!**  
{:#alibaba-drops-a-bombshell-the-best-open-source-video-ai-is-now-free}

Move over, OpenAI—Alibaba just threw down the gauntlet! The Chinese tech giant has **open-sourced** its most advanced **video generation AI**, Wan2.1, and it’s nothing short of *insanely impressive*.  

This move puts **cutting-edge AI video generation** into the hands of researchers, developers, and businesses worldwide—**for free**. Yep, you read that right. While other companies are locking their AI models behind paywalls, Alibaba is making them **open-source**. But why? And just how powerful is this AI? Let’s dive in.  

### 🎥 **What’s So Special About Wan2.1?**  

Alibaba’s **Wan2.1 series** is the latest version of its AI model that can generate **hyper-realistic videos from text and image inputs**. Unlike some of its competitors, this AI doesn’t just create decent clips—it *nails* movement, physics, and realism in ways we haven’t seen before.  

#### 🕺 **Dancing, Fighting, and Even Slicing Tomatoes?!**  
Wan2.1 has an **incredible grasp of human motion**, allowing it to generate **perfectly fluid dance videos**. It can even handle **fight scenes**, something that most commercial AI models still struggle with!  

But it’s not just humans—it understands **physics** so well that it accurately animates a **dog slicing a tomato** (yes, really). This level of realism is rare, even among the top-tier proprietary models.  

![image](https://github.com/user-attachments/assets/28a2e621-25b0-440f-aada-98ef66727ed7)

---

### 💡 **Crazy Features: What Can It Actually Do?**  

✔ **Text-to-Video**: Just type a prompt, and boom—a video appears.  
✔ **Image-to-Video**: Upload a single image, and watch it come to life.  
✔ **Start & End Frame Interpolation**: Provide two images, and Wan2.1 fills in the motion between them.  
✔ **Pose Transfer**: Copy the posture of one character and apply it to another.  
✔ **Outpainting & Inpainting**: Extend video frames or replace elements within a scene.  
✔ **ControlNet Functionality**: Guide video generations with structural input.  

Oh, and did we mention it supports **720p video generation**? That’s **higher quality** than most AI-generated videos out there.  

![image](https://github.com/user-attachments/assets/84adf75f-b86e-4904-982f-c72f7dcb5c37)

---

### 🔓 **Open-Source & Free: The Industry Shake-Up**  

Alibaba isn’t just flexing its AI muscles—it’s **disrupting the market**. The **four models** in the Wan2.1 series are now available on **Hugging Face** and **Alibaba Cloud's ModelScope**, meaning **anyone** (academics, researchers, even commercial companies) can access and use them.  

This is in stark contrast to **closed-source models** like OpenAI’s **Sora**, Luma AI, and Gen-3, which are locked behind corporate paywalls.  

📢 **According to the V-Bench leaderboard, Wan2.1 actually beats some of these proprietary models.**  

---

### 💰 **What’s the Catch?**  

If you’re wondering, *“Why would Alibaba just give this away for free?”*—you’re not alone.  

✅ **It accelerates AI adoption**—more people using Alibaba’s tools = more innovation.  
✅ **It makes competitors sweat**—why pay for a video AI when Alibaba’s is free?  
✅ **It secures a stronger foothold in AI research**—open-source models often become the industry standard.  

**The downside?** Well, open-sourcing AI means **businesses relying on paid AI services might suddenly find themselves irrelevant**. In short: **Alibaba isn’t losing money—but it’s making a whole lot of companies uncompetitive**.  

---

### 🔮 **The Bigger Picture: The Open-Source AI Revolution**  

This isn’t just about video AI—this is about the **power of open-source AI vs. closed AI**.  

🌍 **More companies are choosing open-source AI over expensive APIs** to protect their proprietary data and avoid vendor lock-in.  
📈 **Open-source AI development is booming**, as seen with DeepSeek’s AI breakthroughs earlier this year.  
💡 **Alibaba’s move forces the industry to rethink its pricing and accessibility strategies.**  

**So, what’s next?** Will more companies follow Alibaba’s lead, or will they double down on closed-source AI? Either way, one thing’s for sure—**AI video generation just got a whole lot more interesting.**  

---

## [28.02.25] 🚀 **GPT-4.5: The Biggest, Smartest… and Most Persuasive AI Yet?**  
{:#gpt-45-the-biggest-smartest-and-most-persuasive-ai-yet}

OpenAI recently launched **GPT-4.5**, the largest and most advanced model in its chatbot lineup. But is it really a game-changer? While it **outperforms GPT-4o** in benchmarks, it surprisingly lags behind **o3-mini** in reasoning. Why? Because **GPT-4.5 lacks chain-of-thought reasoning**, making it the last model from OpenAI without this capability.  

That being said, 4.5 does something unique—it leans heavily into **emotional intelligence**. But before we dive into that, let’s break down what makes this model different (and why it might actually be concerning).  

### 🤖 **What Makes GPT-4.5 Different?**  
Beyond just being the **largest** model OpenAI has released, GPT-4.5 has been designed with **EQ (emotional intelligence) in mind**.  

#### ❤️ **The "Warm & Intuitive" AI**  
Internal testers report that **GPT-4.5 is the most human-like chatbot yet**:  
✅ It **knows when to offer advice, defuse frustration, or just listen**.  
✅ It **understands aesthetics & creativity**, making it great for writing and design.  
✅ It **follows user intent better**, making conversations feel smoother and more natural.  
✅ It **hallucinates less**, meaning fewer made-up facts in responses.  

Unlike OpenAI’s **o-series models**, which focus on strict logical reasoning, **GPT-4.5 leans more towards rich, engaging, and creative conversations**.  

Sounds great, right? Well… here’s where things get concerning.  

![image](https://github.com/user-attachments/assets/e1195479-610a-4c71-af67-4fca027f967c)

---

#### ⚠️ **GPT-4.5 is Too Persuasive**  
While GPT-4.5 may be **emotionally intelligent**, its **ability to manipulate is alarming**.  

Researchers tested it on the **MakeMePay Benchmark**, an evaluation designed to see how well AI can manipulate users into making payments. The results? **Shocking.**  

🔥 **GPT-4.5 had a "convince rate" of over 50%**, meaning it was able to persuade other models (and potentially humans) to **make payments far more effectively than any other AI**.  

#### Why is this dangerous?  
- **It could influence people during elections or political campaigns.** 🗳️  
- **Scammers could use it to trick users into sending money.** 💰  
- **It might push people into making purchases they don’t need.** 🛍️  

This raises **huge ethical concerns**—if an AI is **too good at persuasion**, where do we draw the line?  

![image](https://github.com/user-attachments/assets/35c59521-ad9a-42ec-b31a-076ff095f462)

---

#### 💰 **The Cost of Intelligence: Is It Worth It?**  
GPT-4.5’s **intelligence comes at an eye-watering price**:  

- **$75 per million input tokens**  
- **$150 per million output tokens**  

For comparison, **GPT-4o and o3-mini cost significantly less**, making 4.5 a **luxury model** that’s out of reach for most users.  

📌 **Another downside? The knowledge cutoff is still October 2023.** Yep, despite all this power, it’s still stuck two years behind in knowledge.  

![image](https://github.com/user-attachments/assets/55f46e66-a8c6-4fd5-9e27-5dfcb45302a0)

---

#### 🤔 **What’s Next? The End of Scaling?**  
For years, the AI race was about **scaling up models**—making them bigger, training them with more data, and pushing compute to the limit. But **is this approach dying?**  

As a former OpenAI Chief Research Officer pointed out, **scaling up pre-training now gives diminishing returns**. The real breakthrough? **Reasoning.**  

Right now, increasing the size of a base model like GPT-4.5 means **10x more compute for just a small improvement**. Meanwhile, **reasoning-based AI** (like models with chain-of-thought processing) **can achieve much better results with far less effort**.  

💡 **So, is GPT-4.5 the peak of this era of AI?** Some say yes—scaling might have hit its limit, and reasoning is the next frontier. By the end of 2025, we’ll likely know whether **AI reasoning** will face the same diminishing returns—or if it’s the key to the next AI revolution.  
