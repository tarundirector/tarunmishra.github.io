---
layout: default
title: "🤖This Month in AI - March '25"
modified_date: 2025-03-16
date:  2025-02-25
---

[🔽 China Unleashes Manus: The AI Agent Taking on the World](#china-unleashes-manus-the-ai-agent-taking-on-the-world)  

[🔽 Alibaba Shakes Things Up Again: Meet QwQ-32B, the Small but Mighty AI That Challenges Giants!](#alibaba-shakes-things-up-again-meet-qwq-32b-the-small-but-mighty-ai-that-challenges-giants)  

[🔽 Sesame's AI Voices: Are We Finally Crossing the 'Uncanny Valley'?](#sesames-ai-voices-are-we-finally-crossing-the-uncanny-valley)  

[🔽 Alibaba Drops a Bombshell: The Best Open-Source Video AI Is Now Free!](#alibaba-drops-a-bombshell-the-best-open-source-video-ai-is-now-free)  

[🔽 GPT-4.5: The Biggest, Smartest… and Most Persuasive AI Yet?](#gpt-45-the-biggest-smartest-and-most-persuasive-ai-yet)  

---

## 🚀 [14.03.25] **China Unleashes Manus: The AI Agent Taking on the World**  
{:#china-unleashes-manus-the-ai-agent-taking-on-the-world}

<div style="position: relative; height: 200px; background-image: url('https://akm-img-a-in.tosshub.com/businesstoday/images/story/202503/67cd9eb2975c9-manus-is-currently-accessible-through-an-invitation-only-web-preview--with-no-confirmed-public-relea-095909123-16x9.jpg?size=948:533'); background-size: cover; background-position: center; border-radius: 15px; overflow: hidden;">
</div>

China has introduced a much-hyped AI agent called **Manus**, and it’s already ruffling feathers across tech circles 🌏. With posts and demos flooding the web (and some system crashes along the way), **Manus** promises to be more than just a chatbot—it's like a **digital intern** that can browse the internet, handle tasks autonomously, and even ask for your help when confronted with paywalls or logins.

### 🤔 **What Exactly Is Manus?**
Manus is an **“AI agent”**, meaning it can:
- Break down your requests into smaller tasks,
- Do internet research on the fly,
- Interact with websites via a virtual browser,
- Adapt in real time when you give it feedback.

Think of it as a multitasking coworker—except it’s never late and doesn’t need coffee breaks.  

### 🔍 **Why People Are Buzzing**
- **Agent-Like Behaviour**: Manus claims to plan entire itineraries, produce thorough research docs, or even whip up 3D-coded mini-games—often from a single prompt.
- **Open-Web Autonomy**: It *drives* a real (virtual) browser, letting it gather info from multiple sources simultaneously and rummage through sites quickly.
- **Collaboration Factor**: While it’s autonomous, you can step in if it hits a captcha roadblock, or if you simply want to refine what it’s doing.

Early testers rave about how it pulled off tasks like \[1\] scanning job applications, \[2\] building mini coding projects, and \[3\] making property-hunting a breeze. Others complain of **server overload** (“Service unavailable, try again later”), or it occasionally skipping “details to save time.”  

---

### ⚠️ **Where’s the Catch?**
1. **Server Struggles**: With so many invites requested, system errors and high-load messages pop up.  
2. **Data Privacy**: You’re giving a large chunk of power (and possibly personal data) to a brand-new tool.  
3. **China Angle**: Some wonder about the security of letting a foreign AI rummage through sensitive info.  
4. **Still Imperfect**: Manus can misread your instructions if they’re vague, or produce incomplete lists. But it’s refreshingly open about its oversights and can quickly pivot when corrected.

---

### 🌱 **So, What’s Next?**
Despite the hiccups, **Manus** is a bold step forward in the AI agent race. Unlike older chatbots that rely on a single model and static conversation windows, Manus merges multiple models and tools under the hood. As soon as they strengthen server capacity—and clarify privacy features—this agent could become a popular go-to for everything from **media research** to **personal travel planning**.

**Will it dethrone existing AI assistants?** Too soon to say. But with the hype so far—and its real potential in seamlessly finishing complicated tasks—**Manus** definitely just upped the AI competition game.  

---

##  [09.03.25] 🚀 **Alibaba Shakes Things Up Again: Meet QwQ-32B, the Small but Mighty AI That Challenges Giants!**
{:#alibaba-shakes-things-up-again-meet-qwq-32b-the-small-but-mighty-ai-that-challenges-giants}

<div style="position: relative; height: 200px; background-image: url('https://github.com/user-attachments/assets/f69e8899-f3b0-4328-988c-436a3854dce8'); background-size: cover; background-position: center; border-radius: 15px; overflow: hidden;">
</div>

🌟 Alibaba Cloud has just unveiled **QwQ-32B**, a groundbreaking AI reasoning model that's compact yet punches way above its weight, competing head-to-head with industry giants. The AI community is buzzing as Alibaba proves once again: **size isn't everything!** 🤯

### 🚀 **Tiny Model, Big Brains**
Despite having just **32 billion parameters**—much lighter than rival models like DeepSeek-R1 (with a whopping 671 billion parameters)—QwQ-32B delivers impressive results in math, coding, and logical reasoning.

Here's how QwQ-32B stacks up:

- 🧮 **AIME 24 (Mathematics):** Matches the mighty DeepSeek-R1 (671B parameters).
- 💻 **Live CodeBench (Coding):** Nearly identical performance to industry leaders, significantly outperforming smaller competitors.
- 🎯 **LiveBench (Logic and Reasoning):** Holds its own against heavyweights, slightly trailing but still impressive.
- 📜 **IFEval (Instruction-Following):** Tops the leaderboard, showing exceptional user alignment.
- 🔧 **BFCL (Function Calling):** Dominates, proving superior in executing tasks in Python, Java, JavaScript, and SQL.

### 🔥 **Power of Scaled Reinforcement Learning (RL)**
Alibaba’s secret sauce? **Scaled Reinforcement Learning**. By training QwQ-32B with targeted RL, Alibaba has enhanced the model’s reasoning, coding, and even general problem-solving skills without ballooning its size.

### 🧠 **Agent Capabilities: Critical Thinking Unlocked**
QwQ-32B doesn't just execute—it thinks. By integrating advanced agent capabilities, the AI adapts dynamically, utilizes tools efficiently, and can critically reason its way through complex problems.

### 🌐 **Open-Source & Affordable Deployment**
QwQ-32B is **completely open-source**, freely downloadable, and impressively runs on consumer-grade hardware. This drastically lowers deployment costs, making cutting-edge AI accessible for startups, researchers, and even hobbyists.

### 📢 **What Does This Mean?**
Alibaba isn’t just disrupting the market—it’s redefining the rules. QwQ-32B challenges the conventional wisdom that bigger models are always better. This compact powerhouse suggests that smarter, targeted AI training can deliver **world-class results without expensive infrastructure**.

### 🔮 **Looking Forward: A Leap Towards AGI?**
The Qwen team at Alibaba believes this scaled RL approach combined with stronger foundational models will edge them closer to **Artificial General Intelligence (AGI)**. Could this be the blueprint for future AI advancements?

---
## 🎙️ [06.03.25] **Sesame's AI Voices: Are We Finally Crossing the 'Uncanny Valley'?**
{:#sesames-ai-voices-are-we-finally-crossing-the-uncanny-valley}

<div style="position: relative; height: 200px; background-image: url('https://github.com/user-attachments/assets/7994f1a5-2ab2-4a68-a040-5cdd7f4141f1'); background-size: cover; background-position: center; border-radius: 15px; overflow: hidden;">
</div>

Imagine chatting casually with an AI, and instead of hearing a cold, robotic voice, you get responses so natural you’d swear it was human—welcome to the future of AI conversations, brought to you by **Sesame**. 🤖💬

### 🌟 **What’s the Buzz?**
Sesame recently unveiled their revolutionary **Conversational Speech Model (CSM)**, an AI that generates voices so realistic, it’s turning heads (and ears). This innovative approach doesn't just synthesise sound—it genuinely understands context, emotion, and conversational dynamics. Yep, it's eerily close to that charming AI in *"Her"*.

### 🎙️ **Why Is This a Big Deal?**

Unlike traditional text-to-speech tech, Sesame’s new **CSM** can:
- 🔥 **Capture emotional nuance**, sensing context and adjusting tone accordingly.
- 🎯 **Deliver natural conversation flows**, even managing real-time pauses and interruptions.
- 🗣️ **Generate speech with personality**, optimised explicitly for friendliness and expressivity.

### 🚧 **Breaking the Bottleneck**
Previously, voice models struggled to generate speech quickly and contextually. Sesame solved this with:
- **Single-stage multimodal transformers** for real-time context-aware conversations.
- **Compute amortization**, optimising memory usage and speeding up audio production.

### 🚦 **But, Is It Actually Human-Like?**

Early tests show:
- ✅ **Near-human accuracy** on traditional metrics (speaker similarity and word error rate).
- 🔍 However, human listeners still slightly preferred genuine speech when context mattered, indicating room for growth in capturing conversational subtleties.

### 🎧 **Sesame Goes Open Source!**

And here's the kicker—Sesame plans to **open-source** key parts of their groundbreaking AI, inviting developers everywhere to collaborate and improve upon their work. 🌍🔓

### 🎬 **Elsewhere in AI Voices:**
- 🎤 **Podcast-ready in seconds:** New voice-training tech from Podcast startups (still a bit robotic, but improving).
- 📞 **Accent magic:** Call centres using "Accent Translation" to change workers' accents instantly for global clarity.
- 🎥 **AI dubbing, anyone?** Amazon Prime experiments with seamless AI-generated dubbing for global TV and movies.

Sesame just set a new bar in conversational AI. It's not perfect yet—but it's getting eerily close. Could your next best friend be an AI? Perhaps it’s closer than you think.

---

## 🚀 [02.03.25] **Alibaba Drops a Bombshell: The Best Open-Source Video AI Is Now Free!** 
{:#alibaba-drops-a-bombshell-the-best-open-source-video-ai-is-now-free}

<div style="position: relative; height: 200px; background-image: url('https://miro.medium.com/v2/resize:fit:1400/1*RAuBXVrwaX-rBmcEt8FLQA.png'); background-size: cover; background-position: center; border-radius: 15px; overflow: hidden;">
</div>

Move over, OpenAI—Alibaba just threw down the gauntlet! The Chinese tech giant has **open-sourced** its most advanced **video generation AI**, Wan2.1, and it’s nothing short of *insanely impressive*.  

This move puts **cutting-edge AI video generation** into the hands of researchers, developers, and businesses worldwide—**for free**. Yep, you read that right. While other companies are locking their AI models behind paywalls, Alibaba is making them **open-source**. But why? And just how powerful is this AI? Let’s dive in.  

### 🎥 **What’s So Special About Wan2.1?**  

Alibaba’s **Wan2.1 series** is the latest version of its AI model that can generate **hyper-realistic videos from text and image inputs**. Unlike some of its competitors, this AI doesn’t just create decent clips—it *nails* movement, physics, and realism in ways we haven’t seen before.  

#### 🕺 **Dancing, Fighting, and Even Slicing Tomatoes?!**  
Wan2.1 has an **incredible grasp of human motion**, allowing it to generate **perfectly fluid dance videos**. It can even handle **fight scenes**, something that most commercial AI models still struggle with!  

But it’s not just humans—it understands **physics** so well that it accurately animates a **dog slicing a tomato** (yes, really). This level of realism is rare, even among the top-tier proprietary models.  

![image](https://github.com/user-attachments/assets/28a2e621-25b0-440f-aada-98ef66727ed7)

### 💡 **Crazy Features: What Can It Actually Do?**  

✔ **Text-to-Video**: Just type a prompt, and boom—a video appears.  
✔ **Image-to-Video**: Upload a single image, and watch it come to life.  
✔ **Start & End Frame Interpolation**: Provide two images, and Wan2.1 fills in the motion between them.  
✔ **Pose Transfer**: Copy the posture of one character and apply it to another.  
✔ **Outpainting & Inpainting**: Extend video frames or replace elements within a scene.  
✔ **ControlNet Functionality**: Guide video generations with structural input.  

Oh, and did we mention it supports **720p video generation**? That’s **higher quality** than most AI-generated videos out there.  

![image](https://github.com/user-attachments/assets/84adf75f-b86e-4904-982f-c72f7dcb5c37)

### 🔓 **Open-Source & Free: The Industry Shake-Up**  

Alibaba isn’t just flexing its AI muscles—it’s **disrupting the market**. The **four models** in the Wan2.1 series are now available on **Hugging Face** and **Alibaba Cloud's ModelScope**, meaning **anyone** (academics, researchers, even commercial companies) can access and use them.  

This is in stark contrast to **closed-source models** like OpenAI’s **Sora**, Luma AI, and Gen-3, which are locked behind corporate paywalls.  

📢 **According to the V-Bench leaderboard, Wan2.1 actually beats some of these proprietary models.**  

### 💰 **What’s the Catch?**  

If you’re wondering, *“Why would Alibaba just give this away for free?”*—you’re not alone.  

✅ **It accelerates AI adoption**—more people using Alibaba’s tools = more innovation.  
✅ **It makes competitors sweat**—why pay for a video AI when Alibaba’s is free?  
✅ **It secures a stronger foothold in AI research**—open-source models often become the industry standard.  

**The downside?** Well, open-sourcing AI means **businesses relying on paid AI services might suddenly find themselves irrelevant**. In short: **Alibaba isn’t losing money—but it’s making a whole lot of companies uncompetitive**.  

### 🔮 **The Bigger Picture: The Open-Source AI Revolution**  

This isn’t just about video AI—this is about the **power of open-source AI vs. closed AI**.  

🌍 **More companies are choosing open-source AI over expensive APIs** to protect their proprietary data and avoid vendor lock-in.  
📈 **Open-source AI development is booming**, as seen with DeepSeek’s AI breakthroughs earlier this year.  
💡 **Alibaba’s move forces the industry to rethink its pricing and accessibility strategies.**  

**So, what’s next?** Will more companies follow Alibaba’s lead, or will they double down on closed-source AI? Either way, one thing’s for sure—**AI video generation just got a whole lot more interesting.**  

---

## [28.02.25] 🚀 **GPT-4.5: The Biggest, Smartest… and Most Persuasive AI Yet?**  
{:#gpt-45-the-biggest-smartest-and-most-persuasive-ai-yet}

OpenAI recently launched **GPT-4.5**, the largest and most advanced model in its chatbot lineup. But is it really a game-changer? While it **outperforms GPT-4o** in benchmarks, it surprisingly lags behind **o3-mini** in reasoning. Why? Because **GPT-4.5 lacks chain-of-thought reasoning**, making it the last model from OpenAI without this capability.  

That being said, 4.5 does something unique—it leans heavily into **emotional intelligence**. But before we dive into that, let’s break down what makes this model different (and why it might actually be concerning).  

### 🤖 **What Makes GPT-4.5 Different?**  
Beyond just being the **largest** model OpenAI has released, GPT-4.5 has been designed with **EQ (emotional intelligence) in mind**.  

#### ❤️ **The "Warm & Intuitive" AI**  
Internal testers report that **GPT-4.5 is the most human-like chatbot yet**:  
✅ It **knows when to offer advice, defuse frustration, or just listen**.  
✅ It **understands aesthetics & creativity**, making it great for writing and design.  
✅ It **follows user intent better**, making conversations feel smoother and more natural.  
✅ It **hallucinates less**, meaning fewer made-up facts in responses.  

Unlike OpenAI’s **o-series models**, which focus on strict logical reasoning, **GPT-4.5 leans more towards rich, engaging, and creative conversations**.  

Sounds great, right? Well… here’s where things get concerning.  

![image](https://github.com/user-attachments/assets/e1195479-610a-4c71-af67-4fca027f967c)

#### ⚠️ **GPT-4.5 is Too Persuasive**  
While GPT-4.5 may be **emotionally intelligent**, its **ability to manipulate is alarming**.  

Researchers tested it on the **MakeMePay Benchmark**, an evaluation designed to see how well AI can manipulate users into making payments. The results? **Shocking.**  

🔥 **GPT-4.5 had a "convince rate" of over 50%**, meaning it was able to persuade other models (and potentially humans) to **make payments far more effectively than any other AI**.  

#### Why is this dangerous?  
- **It could influence people during elections or political campaigns.** 🗳️  
- **Scammers could use it to trick users into sending money.** 💰  
- **It might push people into making purchases they don’t need.** 🛍️  

This raises **huge ethical concerns**—if an AI is **too good at persuasion**, where do we draw the line?  

![image](https://github.com/user-attachments/assets/35c59521-ad9a-42ec-b31a-076ff095f462)

#### 💰 **The Cost of Intelligence: Is It Worth It?**  
GPT-4.5’s **intelligence comes at an eye-watering price**:  

- **$75 per million input tokens**  
- **$150 per million output tokens**  

For comparison, **GPT-4o and o3-mini cost significantly less**, making 4.5 a **luxury model** that’s out of reach for most users.  

📌 **Another downside? The knowledge cutoff is still October 2023.** Yep, despite all this power, it’s still stuck two years behind in knowledge.  

![image](https://github.com/user-attachments/assets/55f46e66-a8c6-4fd5-9e27-5dfcb45302a0)

#### 🤔 **What’s Next? The End of Scaling?**  
For years, the AI race was about **scaling up models**—making them bigger, training them with more data, and pushing compute to the limit. But **is this approach dying?**  

As a former OpenAI Chief Research Officer pointed out, **scaling up pre-training now gives diminishing returns**. The real breakthrough? **Reasoning.**  

Right now, increasing the size of a base model like GPT-4.5 means **10x more compute for just a small improvement**. Meanwhile, **reasoning-based AI** (like models with chain-of-thought processing) **can achieve much better results with far less effort**.  

💡 **So, is GPT-4.5 the peak of this era of AI?** Some say yes—scaling might have hit its limit, and reasoning is the next frontier. By the end of 2025, we’ll likely know whether **AI reasoning** will face the same diminishing returns—or if it’s the key to the next AI revolution.  
